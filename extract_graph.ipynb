{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "## Input data directory\n",
    "data_dir = \"cureus\"\n",
    "inputdirectory = Path(f\"./data_input/{data_dir}\")\n",
    "## This is where the output csv files will be written\n",
    "out_dir = data_dir\n",
    "outputdirectory = Path(f\"./data_output/{out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks =  31\n",
      "due to the prominent spurious correlation problem (Geirhos\n",
      "\n",
      "et al. 2018; Hu et al. 2022), i.e., non-causal correlations\n",
      "\n",
      "learned from the limited training annotations. The trained\n",
      "\n",
      "model is supposed to only exploit AU-specific features\n",
      "\n",
      "representing the corresponding facial appearance changes,\n",
      "\n",
      "which is much harder to achieve with non-negligible spuri-\n",
      "\n",
      "ous correlation. First, the model aims to estimate the inten-\n",
      "\n",
      "sity values for multiple AUs simultaneously, and thus AU\n",
      "\n",
      "co-occurrences may lead to spurious correlation. As in Fig. 1\n",
      "\n",
      "(b), the model is supposed to capture both facial appearance\n",
      "\n",
      "changes from the cheek region for AU6 and lip corner re-\n",
      "\n",
      "gion for AU12. However, their co-occurrence patterns (e.g.,\n",
      "\n",
      "both AUs with the same intensity) that frequently occur in\n",
      "\n",
      "keyframe annotations may mislead the model into learning\n",
      "\n",
      "features of only one of them (Shi et al. 2022), e.g., using fea-\n",
      "\n",
      "tures from the lip corner region to represent both AUs and\n",
      "\n",
      "ignoring those from the cheek region. Second, as in Fig. 1\n",
      "\n",
      "(c), the lack of annotations magnifies the spurious correla-\n",
      "\n",
      "tion caused by subject variation. E.g., suppose the annotated\n",
      "\n",
      "frames are mostly women with AU12 at high-intensity lev-\n",
      "\n",
      "els and men with AU12 at low-intensity levels. In that case,\n",
      "\n",
      "the model may be misled to use non-causal gender features\n",
      "\n",
      "instead of AU features to represent the intensity of AU12.We argue that the spurious correlation problem hinders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Dir PDF Loader\n",
    "# loader = PyPDFDirectoryLoader(inputdirectory)\n",
    "## File Loader\n",
    "# loader = PyPDFLoader(\"./data/MedicalDocuments/orf-path_health-n1.pdf\")\n",
    "loader = DirectoryLoader(inputdirectory, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "pages = splitter.split_documents(documents)\n",
    "print(\"Number of chunks = \", len(pages))\n",
    "print(pages[3].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module imported successfully\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目路径到sys.path\n",
    "project_path = 'D:/知识图谱与认知智能/大作业/knowledge_graph-main/knowledge_graph-main'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "# 加载 df_helpers 模块\n",
    "module_path = os.path.join(project_path, 'helpers', 'df_helpers.py')\n",
    "spec = importlib.util.spec_from_file_location(\"helpers.df_helpers\", module_path)\n",
    "df_helpers = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(df_helpers)\n",
    "\n",
    "# 使用模块中的函数\n",
    "#documents2Dataframe = df_helpers.documents2Dataframe\n",
    "print(\"Module imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe of all the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trend-Aware Supervision: On Learning Invarianc...</td>\n",
       "      <td>data_input\\cureus\\5.txt</td>\n",
       "      <td>3898818987224bd68c5f7adc0ae75fbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lem by raising trend awareness during training...</td>\n",
       "      <td>data_input\\cureus\\5.txt</td>\n",
       "      <td>a2124b6d251740ea8f21798f8bdcd795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>†Corresponding author.Copyright © 2024, Associ...</td>\n",
       "      <td>data_input\\cureus\\5.txt</td>\n",
       "      <td>3d4a933a2a284dff9100dd33f051422d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>due to the prominent spurious correlation prob...</td>\n",
       "      <td>data_input\\cureus\\5.txt</td>\n",
       "      <td>be2f5f07257b46bb96e6805d8057cebd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>instead of AU features to represent the intens...</td>\n",
       "      <td>data_input\\cureus\\5.txt</td>\n",
       "      <td>30c4fc379a664f6190d98a8ee6643cb3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   source  \\\n",
       "0  Trend-Aware Supervision: On Learning Invarianc...  data_input\\cureus\\5.txt   \n",
       "1  lem by raising trend awareness during training...  data_input\\cureus\\5.txt   \n",
       "2  †Corresponding author.Copyright © 2024, Associ...  data_input\\cureus\\5.txt   \n",
       "3  due to the prominent spurious correlation prob...  data_input\\cureus\\5.txt   \n",
       "4  instead of AU features to represent the intens...  data_input\\cureus\\5.txt   \n",
       "\n",
       "                           chunk_id  \n",
       "0  3898818987224bd68c5f7adc0ae75fbd  \n",
       "1  a2124b6d251740ea8f21798f8bdcd795  \n",
       "2  3d4a933a2a284dff9100dd33f051422d  \n",
       "3  be2f5f07257b46bb96e6805d8057cebd  \n",
       "4  30c4fc379a664f6190d98a8ee6643cb3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from helpers.df_helpers import documents2Dataframe\n",
    "df = documents2Dataframe(pages)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function uses the helpers/prompt function to extract concepts from text\n",
    "from helpers.df_helpers import df2Graph\n",
    "from helpers.df_helpers import graph2Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If regenerate is set to True then the dataframes are regenerated and Both the dataframes are written in the csv format so we dont have to calculate them again. \n",
    "\n",
    "        dfne = dataframe of edges\n",
    "\n",
    "        df = dataframe of chunks\n",
    "\n",
    "\n",
    "Else the dataframes are read from the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\社会主义接班人\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ERROR ### Here is the buggy response:  [\n",
      "   {\n",
      "       \"node_1\": \"image\",\n",
      "       \"node_2\": \"segment\",\n",
      "       \"edge\": \"Images are contained in each segment\"\n",
      "   },\n",
      "   {\n",
      "       \"node_1\": \"intensity label\",\n",
      "       \"node_2\": \"AU\",\n",
      "       \"edge\": \"Intensity labels are given for the AU in the first and the last images\"\n",
      "   },\n",
      "   {\n",
      "       \"node_1\": \"intensity label\",\n",
      "       \"node_2\": \"normalized range\",\n",
      "       \"edge\": \"Intensity labels are uniformly normalized from range [0, 5] to range [0, 1]\"\n",
      "   },\n",
      "   {\n",
      "       \"node_1\": \"goal\",\n",
      "       \"node_2\": \"optimal Θ\",\n",
      "       \"edge\": \"Goal is to learn an optimal Θ for an image-based AU intensity estimation model\"\n",
      "   },\n",
      "   {\n",
      "       \"node_1\": \"batch\",\n",
      "       \"node_2\": \"pre-processed segments\",\n",
      "       \"edge\": \"A batch of pre-processed segments is taken as input in the training stage\"\n",
      "   },\n",
      "   {\n",
      "       \"node_1\": \"image\",\n",
      "       \"node_2\": \"backbone network\",\n",
      "       \"edge\": \"Each image is fed into a backbone network to extract global feature\"\n",
      "   },\n",
      "   {\n",
      "       \"node_1\": \"global feature\",\n",
      "       \"node_2\": \"AU features\",\n",
      "       \"edge\": \"Global feature is used to obtain AU features\"\n",
      "   },\n",
      "   {\n",
      "       \"node_1\": \"AU features\",\n",
      "       \"node_2\": \"spatial attention layers\",\n",
      "       \"edge\": \"Spatial attention layers are applied to the extracted AU features\"\n",
      "   },\n",
      "   {\n",
      "       \"node_1\": \"AU features\",\n",
      "       \"node_2\": \"regression loss function\",\n",
      "       \"edge\": \"Regression loss function acts as direct supervision for the AU features\"\n",
      "   }\n",
      "   {\n",
      "       \"node_1\": \"keyframes\",\n",
      "       \"node_2\": \"segment\",\n",
      "       \"edge\": \"Two annotated keyframes in each segment\"\n",
      "   }\n",
      "] \n",
      "\n",
      "\n",
      "(313, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>edge</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trend-aware supervision</td>\n",
       "      <td>semi-supervised au intensity estimation</td>\n",
       "      <td>Trend-Aware Supervision (TAS) is proposed as a...</td>\n",
       "      <td>3898818987224bd68c5f7adc0ae75fbd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trend-aware supervision</td>\n",
       "      <td>keyframe annotations</td>\n",
       "      <td>Trend-Aware Supervision (TAS) utilizes trend i...</td>\n",
       "      <td>3898818987224bd68c5f7adc0ae75fbd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>trend-aware supervision</td>\n",
       "      <td>au-specific features</td>\n",
       "      <td>Trend-Aware Supervision (TAS) aims to learn AU...</td>\n",
       "      <td>3898818987224bd68c5f7adc0ae75fbd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semi-supervised au intensity estimation</td>\n",
       "      <td>keyframe annotations</td>\n",
       "      <td>Semi-supervised AU intensity estimation uses o...</td>\n",
       "      <td>3898818987224bd68c5f7adc0ae75fbd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>semi-supervised au intensity estimation</td>\n",
       "      <td>spurious correlation problem</td>\n",
       "      <td>The lack of annotations in semi-supervised AU ...</td>\n",
       "      <td>3898818987224bd68c5f7adc0ae75fbd</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    node_1  \\\n",
       "0                  trend-aware supervision   \n",
       "1                  trend-aware supervision   \n",
       "2                  trend-aware supervision   \n",
       "3  semi-supervised au intensity estimation   \n",
       "4  semi-supervised au intensity estimation   \n",
       "\n",
       "                                    node_2  \\\n",
       "0  semi-supervised au intensity estimation   \n",
       "1                     keyframe annotations   \n",
       "2                     au-specific features   \n",
       "3                     keyframe annotations   \n",
       "4             spurious correlation problem   \n",
       "\n",
       "                                                edge  \\\n",
       "0  Trend-Aware Supervision (TAS) is proposed as a...   \n",
       "1  Trend-Aware Supervision (TAS) utilizes trend i...   \n",
       "2  Trend-Aware Supervision (TAS) aims to learn AU...   \n",
       "3  Semi-supervised AU intensity estimation uses o...   \n",
       "4  The lack of annotations in semi-supervised AU ...   \n",
       "\n",
       "                           chunk_id  count  \n",
       "0  3898818987224bd68c5f7adc0ae75fbd      4  \n",
       "1  3898818987224bd68c5f7adc0ae75fbd      4  \n",
       "2  3898818987224bd68c5f7adc0ae75fbd      4  \n",
       "3  3898818987224bd68c5f7adc0ae75fbd      4  \n",
       "4  3898818987224bd68c5f7adc0ae75fbd      4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To regenerate the graph with LLM, set this to True\n",
    "regenerate = True\n",
    "\n",
    "if regenerate:\n",
    "    concepts_list = df2Graph(df, model='gpt-4')\n",
    "    dfg1 = graph2Df(concepts_list)\n",
    "    if not os.path.exists(outputdirectory):\n",
    "        os.makedirs(outputdirectory)\n",
    "    \n",
    "    dfg1.to_csv(outputdirectory/\"3_graph.csv\", sep=\"|\", index=False)\n",
    "    df.to_csv(outputdirectory/\"3_chunks.csv\", sep=\"|\", index=False)\n",
    "else:\n",
    "    dfg1 = pd.read_csv(outputdirectory/\"graph.csv\", sep=\"|\")\n",
    "\n",
    "dfg1.replace(\"\", np.nan, inplace=True)\n",
    "dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "dfg1['count'] = 4 \n",
    "## Increasing the weight of the relation to 4. \n",
    "## We will assign the weight of 1 when later the contextual proximity will be calculated.  \n",
    "print(dfg1.shape)\n",
    "dfg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating contextual proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>facial appearance</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6326</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>frame</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>4</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>intra-trend ranking awareness</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>6</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>intra-trend speed awareness</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>loss function</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     node_1                         node_2  \\\n",
       "6325    ∆fc              facial appearance   \n",
       "6326    ∆fc                          frame   \n",
       "6327    ∆fc  intra-trend ranking awareness   \n",
       "6328    ∆fc    intra-trend speed awareness   \n",
       "6329    ∆fc                  loss function   \n",
       "\n",
       "                                               chunk_id  count  \\\n",
       "6325  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...      2   \n",
       "6326  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...      4   \n",
       "6327  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...      6   \n",
       "6328  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...      2   \n",
       "6329  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...      2   \n",
       "\n",
       "                      edge  \n",
       "6325  contextual proximity  \n",
       "6326  contextual proximity  \n",
       "6327  contextual proximity  \n",
       "6328  contextual proximity  \n",
       "6329  contextual proximity  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## Melt the dataframe into a list of nodes\n",
    "    dfg_long = pd.melt(\n",
    "        df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "    )\n",
    "    dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "    # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "    dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "    # drop self loops\n",
    "    self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "    dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "    ## Group and count edges.\n",
    "    dfg2 = (\n",
    "        dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "    dfg2.replace(\"\", np.nan, inplace=True)\n",
    "    dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "    # Drop edges with 1 count\n",
    "    dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "    dfg2[\"edge\"] = \"contextual proximity\"\n",
    "    return dfg2\n",
    "\n",
    "\n",
    "dfg2 = contextual_proximity(dfg1)\n",
    "dfg2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>edge</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>method</td>\n",
       "      <td>45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>sgd</td>\n",
       "      <td>45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>t</td>\n",
       "      <td>45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>λrank</td>\n",
       "      <td>45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>λspd</td>\n",
       "      <td>45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>facial appearance</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>The relationship between ∆fc and the facial ap...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>frame</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>intra-trend ranking awareness</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>intra-trend speed awareness</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>∆fc</td>\n",
       "      <td>loss function</td>\n",
       "      <td>cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2995 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     node_1                         node_2  \\\n",
       "0        16                         method   \n",
       "1        16                            sgd   \n",
       "2        16                              t   \n",
       "3        16                          λrank   \n",
       "4        16                           λspd   \n",
       "...     ...                            ...   \n",
       "2990    ∆fc              facial appearance   \n",
       "2991    ∆fc                          frame   \n",
       "2992    ∆fc  intra-trend ranking awareness   \n",
       "2993    ∆fc    intra-trend speed awareness   \n",
       "2994    ∆fc                  loss function   \n",
       "\n",
       "                                               chunk_id  \\\n",
       "0     45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...   \n",
       "1     45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...   \n",
       "2     45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...   \n",
       "3     45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...   \n",
       "4     45889a5b81fa426bb6d03ab275b2a811,45889a5b81fa4...   \n",
       "...                                                 ...   \n",
       "2990  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...   \n",
       "2991  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...   \n",
       "2992  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...   \n",
       "2993  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...   \n",
       "2994  cd8ba14b35f54a6cb9f7e8c5dd696468,cd8ba14b35f54...   \n",
       "\n",
       "                                                   edge  count  \n",
       "0                                  contextual proximity      2  \n",
       "1                                  contextual proximity      2  \n",
       "2                                  contextual proximity      3  \n",
       "3                                  contextual proximity      2  \n",
       "4                                  contextual proximity      2  \n",
       "...                                                 ...    ...  \n",
       "2990  The relationship between ∆fc and the facial ap...      6  \n",
       "2991                               contextual proximity      4  \n",
       "2992                               contextual proximity      6  \n",
       "2993                               contextual proximity      2  \n",
       "2994                               contextual proximity      2  \n",
       "\n",
       "[2995 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "dfg = (\n",
    "    dfg.groupby([\"node_1\", \"node_2\"])\n",
    "    .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "dfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the NetworkX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "## Add nodes to the graph\n",
    "for node in nodes:\n",
    "    G.add_node(\n",
    "        str(node)\n",
    "    )\n",
    "\n",
    "## Add edges to the graph\n",
    "for index, row in dfg.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"node_1\"]),\n",
    "        str(row[\"node_2\"]),\n",
    "        title=row[\"edge\"],\n",
    "        weight=row['count']/4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate communities for coloring the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Communities =  19\n",
      "[['16', 'adult subjects', 'annotations', 'automatic differentiation', 'batch size', 'bp4d', 'datasets', 'disfa', 'dlib', 'facial images', 'facs-quantified au intensity labels', 'fera 2015 challenge', 'fully-supervised methods', 'intra-class correlation (icc(3,1))', 'learning rate', 'mean absolute error (mae)', 'method', 'nvidia a100 tensor core gpu', 'paszke', 'pytorch', 'segmenti, j', 'semi-supervised au inten- sity estimation methods', 'sgd', 't', 't, k', 't, α, λrank, λspd', 'weight decay', 'α', 'λrank', 'λspd', 'λsub'], ['6th international conference on learning representations', 'asian conference on computer vision', 'bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database', 'context-aware feature and label fusion for facial action unit intensity estimation with partially labeled data', 'deep facial action unit recognition and intensity estimation', 'ieee conference on computer vision and pattern recognition', 'ieee transactions on affective computing', 'ieee transactions on image processing', 'ieee/cvf international conference on computer vision', 'image and vision computing', 'mixup: beyond empirical risk minimization', 're-net: a relation embedded deep model for au occurrence and intensity estimation', 'weakly-supervised deep convolutional neural network learning for facial action unit intensity estimation'], ['a0', 'a1', 'a2', 'a5', 'a6', 'ablation study', 'adjacent keyframes', 'affective computing', 'au', 'au classes', 'au co-occurrences', 'au feature', 'au feature extraction', 'au features', 'au features f au', 'au features of the same class with the same intensity label', 'au intensity estimation', 'au intensity estimation model', 'au intensity estimation task', 'au-specific facial appearance', 'au-specific facial appearance changes', 'au-specific feature learning', 'au-specific features', 'au12', 'au6', 'augmented virtual image-target pairs', 'aus', 'awareness', 'backbone network', 'baseline', 'bormir', 'changing amplitudes', 'changing amplitudes of au features', 'co-occurrence patterns', 'correlations', 'dataset', 'difficulty', 'driver fatigue monitoring', 'dynamic graph convolution', 'els', 'empirical study', 'estimated intensity results', 'estimated results', 'euclidean distance', 'experiments', 'extra computational or storage costs', 'facial action unit intensity estimation', 'facial action unit intensity estimation via semantic correspondence learning', 'facial action units (au)', 'facial appearance', 'facial appearance changes', 'facial appearance features', 'facial behavior analysis', 'facial behaviors', 'facs', 'facs annotations', 'features', 'fig. 5', 'figure 5', 'frame', 'frames', 'g2rl', 'geirhos et al. 2018; hu et al. 2022', 'gender features', 'geometry-guided representation learning', 'hbnheatmap2dcccnn-itcnn', 'hyper-parameters', 'icc mae', 'identities', 'image', 'images', 'input segment', 'intensity', 'intensity estimation', 'intensity estimation invariance', 'intensity label', 'intensity labels', 'intensity of au12', 'intensity results', 'intensity values', 'intensity values of au', 'inter-trend subject awareness', 'intermediate intensity', 'intra-trend and inter-trend awareness', 'intra-trend ranking awareness', 'intra-trend speed awareness', 'joint facial', 'kbss', 'keyframe annotations', 'keyframe-based semi-supervised au intensity estimation problem', 'keyframe-based setting', 'keyframes', 'learning invariant au-specific features', 'limited annotations', 'limited training annotations', 'local trend', 'local trends', 'loss function', 'lstm-based method', 'lsub', 'men', 'methodbp4ddisfaiccmaeiccmaes1', 'mixup operation', 'mlp', 'mlp layers', 'model', 'model a1', 'model a2', 'model a3', 'model a4', 'model a5', 'model a6', 'multi au labels', 'network architecture', 'non-causal correlations', 'ordinal information', 'ordinal relevance multi-instance regression', 'osvr', 'oursbp4ddisfa-', 'pain estimation', 'partially labeled data', 'performance', 'performance improvement', 'pre-extracted features', 'previous works', 'proposed trend-aware supervision', 'pyramid feature attention network', 'ranking awareness', 're-net', 'regression layers', 'regression loss function', 'relevant value', 'resnet34', 's1', 's2', 's3', 'saliency detection', 'scc', 'segments', 'single au label', 'spatial attention layers', 'specific au', 'speed awareness', 'spurious correlation', 'spurious correlation problem', 'spurious ones', 'subject', 'subject awareness', 'subject identity', 'subject variation', 'subject-related features', 'supervision', 't-sne visualization', 'table 4', 'tian, f.', 'trade-off hyper-parameter', 'training', 'training data', 'training models', 'trend awareness', 'trend-aware supervision', 'trend-aware supervision (tas)', 'trend-aware supervision scheme', 'vicinity relation', 'video sequences', 'virtual image-target pairs', 'women', 'λ', '∆fc'], ['adaptive bayesian source separation method', 'spontaneous facial action intensity database'], ['almaev, t.', 'berglund, m.', 'bulat, a.', 'chan, j. h.', 'cohn, j. f.', 'conference on computer vision and pattern recognition', 'cui, z.', 'daunhawer, i.', 'fleiss, j. l.', 'girard, j. m.', 'hao, l.', 'honkala, m.', 'ieee international conference and workshops on automatic face and gesture recognition', 'ji, q.', 'jiang, f.', 'king, i.', 'kwok, j. t.', 'leung, a. c.', 'mckeown, g.', 'mehu, m.', 'pan, b.', 'pantic, m.', 'pasupa, k.', 'pavlovic, v.', 'raiko, t.', 'rasmus, a.', 'rudovic, o.', 'sanchez, e.', 'sanyal, a.', 'schuller, b.', 'shen, r.', 'shi, y.', 'shrout, p. e.', 'song, t.', 's´anchez-lozano, e.', 'torr, p.', 'tzimiropoulos, g.', 'valpola, h.', 'valstar, m.', 'valstar, m. f.', 'vogt, j. e.', 'walecki, r.', 'wang, c.', 'wang, s.', 'wang, y.', 'wu, s.', 'yang, h.', 'yin, l.', 'zaganidis, a.', 'zheng, w.'], ['annotators', 'automatic au intensity estimation', 'facial landmark heatmap regression problem', 'facs-quantified annotations', 'fan et al. 2020', 'fan, lam, and li 2020', 'hbn', 'kaltwang, todorovic, and pantic 2015', 'latent dependencies', 'linh tran et al. 2017', 'location information', 'manually annotating a large amount of training data', 'prior knowledge', 'probabilistic graphical models', 'semi-supervised au intensity estimation', 'video sequence', 'wang, hao, and ji 2018'], ['au intensity', 'spurious features'], ['automatic face and gesture recognition', 'deep learning'], ['automatic facial action coding', 'semi-parametric variational autoencoders'], ['cflfrandconours', 'disfabp4d', 'kjre (6%)kbss', 'ladder', 'osvrbormir', 'osvricc↑mae↓bormir'], ['continuous facial behavior estimation', 'doubly sparse relevance vector machine', 'sparse relevance vector machine'], ['deep residual learning for image recognition', 'imagenet-trained cnns'], ['dynamic bayesian network', 'facial action units'], ['facial action coding system', 'facial action unit intensity prediction and region localisation'], ['frame indexes', 't pairs'], ['ieee', 'international joint conferences on artificial intelligence'], ['kjre', 'semi-supervised methods'], ['ladder network', 'semi-supervised learning'], ['multi-task generalization', 'regularizing spurious correlation']]\n"
     ]
    }
   ],
   "source": [
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe for community colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>color</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>#57dba4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult subjects</td>\n",
       "      <td>#57dba4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>annotations</td>\n",
       "      <td>#57dba4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>automatic differentiation</td>\n",
       "      <td>#57dba4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>batch size</td>\n",
       "      <td>#57dba4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>semi-supervised methods</td>\n",
       "      <td>#5795db</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>ladder network</td>\n",
       "      <td>#db57cc</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>semi-supervised learning</td>\n",
       "      <td>#db57cc</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>multi-task generalization</td>\n",
       "      <td>#dbb257</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>regularizing spurious correlation</td>\n",
       "      <td>#dbb257</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>313 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  node    color  group\n",
       "0                                   16  #57dba4      1\n",
       "1                       adult subjects  #57dba4      1\n",
       "2                          annotations  #57dba4      1\n",
       "3            automatic differentiation  #57dba4      1\n",
       "4                           batch size  #57dba4      1\n",
       "..                                 ...      ...    ...\n",
       "308            semi-supervised methods  #5795db     17\n",
       "309                     ladder network  #db57cc     18\n",
       "310           semi-supervised learning  #db57cc     18\n",
       "311          multi-task generalization  #dbb257     19\n",
       "312  regularizing spurious correlation  #dbb257     19\n",
       "\n",
       "[313 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "palette = \"hls\"\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add colors to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in colors.iterrows():\n",
    "    G.nodes[row['node']]['group'] = row['group']\n",
    "    G.nodes[row['node']]['color'] = row['color']\n",
    "    G.nodes[row['node']]['size'] = G.degree[row['node']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "graph_output_directory = \"./docs/3_index.html\"\n",
    "\n",
    "net = Network(\n",
    "    notebook=False,\n",
    "    # bgcolor=\"#1a1a1a\",\n",
    "    cdn_resources=\"remote\",\n",
    "    height=\"900px\",\n",
    "    width=\"100%\",\n",
    "    select_menu=True,\n",
    "    # font_color=\"#cccccc\",\n",
    "    filter_menu=False,\n",
    ")\n",
    "\n",
    "net.from_nx(G)\n",
    "# net.repulsion(node_distance=150, spring_length=400)\n",
    "net.force_atlas_2based(central_gravity=0.015, gravity=-31)\n",
    "# net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "net.show_buttons(filter_=[\"physics\"])\n",
    "html_content = net.generate_html()\n",
    "\n",
    "# Write the HTML content to a file with UTF-8 encoding\n",
    "with open(graph_output_directory, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "# net.show(graph_output_directory, notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # 保存节点信息\n",
    "# nodes_data = []\n",
    "# for node in G.nodes(data=True):\n",
    "#     nodes_data.append({\n",
    "#         'node': node[0],\n",
    "#         'group': node[1].get('group'),\n",
    "#         'color': node[1].get('color'),\n",
    "#         'size': node[1].get('size')\n",
    "#     })\n",
    "\n",
    "# df_nodes = pd.DataFrame(nodes_data)\n",
    "# df_nodes.to_csv(\"nodes_data.csv\", index=False)\n",
    "\n",
    "# # 保存边信息\n",
    "# edges_data = []\n",
    "# for edge in G.edges(data=True):\n",
    "#     edges_data.append({\n",
    "#         'node_1': edge[0],\n",
    "#         'node_2': edge[1],\n",
    "#         'weight': edge[2].get('weight')\n",
    "#     })\n",
    "\n",
    "# df_edges = pd.DataFrame(edges_data)\n",
    "# df_edges.to_csv(\"edges_data.csv\", index=False)\n",
    "# communities_data = []\n",
    "# for group, community in enumerate(communities, 1):\n",
    "#     for node in community:\n",
    "#         communities_data.append({'node': node, 'group': group})\n",
    "\n",
    "# df_communities = pd.DataFrame(communities_data)\n",
    "# df_communities.to_csv(\"communities_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
