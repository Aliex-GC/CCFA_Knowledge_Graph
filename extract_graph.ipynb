{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "## Input data directory\n",
    "data_dir = \"cureus\"\n",
    "inputdirectory = Path(f\"./data_input/{data_dir}\")\n",
    "## This is where the output csv files will be written\n",
    "out_dir = data_dir\n",
    "outputdirectory = Path(f\"./data_output/{out_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:15<00:00, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks =  27\n",
      "tion of random horizontal flip for the image while not ap-\n",
      "\n",
      "plying any augmentation to the text (Wang et al. 2020; Chen\n",
      "\n",
      "et al. 2022; Ding et al. 2021). In this study, we comprehen-sively evaluate various data augmentation strategies, thereby\n",
      "\n",
      "deriving a powerful data augmentation strategy for TBPS.2) Loss function. Designing rational and practical loss\n",
      "\n",
      "functions is critical to improving performance and has been\n",
      "\n",
      "an increasingly active research direction in TBPS commu-\n",
      "\n",
      "nity (Zhang and Lu 2018; Bai et al. 2023a). We take CLIP as\n",
      "\n",
      "a hotbed and conduct a series of probing studies to analyze\n",
      "\n",
      "the effectiveness of various loss functions in TBPS. Unlike\n",
      "\n",
      "the loss functions in existing TBPS methods that are well-\n",
      "\n",
      "designed mainly from exploring the TBPS task and belong\n",
      "\n",
      "to the task-oriented loss functions, the loss functions probed\n",
      "\n",
      "in this study are primarily inspired by VLP communities and\n",
      "\n",
      "are pretty generic to various cross-modal tasks.These empirical studies above, combined with other valu-\n",
      "\n",
      "able tricks detailed in later sections, enable us to develop\n",
      "\n",
      "a strong TBPS-CLIP baseline. Unlike other methods of de-\n",
      "\n",
      "signing sophisticated modules, TBPS-CLIP attains compet-\n",
      "\n",
      "itive performance under a very lightweight and low-cost ar-\n",
      "\n",
      "chitecture. It blends only a few common training tricks, data\n",
      "\n",
      "augmentations, and loss functions into CLIP. To thoroughly\n",
      "\n",
      "verify the effectiveness and generalization of TBPS-CLIP,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Dir PDF Loader\n",
    "# loader = PyPDFDirectoryLoader(inputdirectory)\n",
    "## File Loader\n",
    "# loader = PyPDFLoader(\"./data/MedicalDocuments/orf-path_health-n1.pdf\")\n",
    "loader = DirectoryLoader(inputdirectory, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "pages = splitter.split_documents(documents)\n",
    "print(\"Number of chunks = \", len(pages))\n",
    "print(pages[3].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module imported successfully\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# 添加项目路径到sys.path\n",
    "project_path = 'D:/知识图谱与认知智能/大作业/knowledge_graph-main/knowledge_graph-main'\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "\n",
    "# 加载 df_helpers 模块\n",
    "module_path = os.path.join(project_path, 'helpers', 'df_helpers.py')\n",
    "spec = importlib.util.spec_from_file_location(\"helpers.df_helpers\", module_path)\n",
    "df_helpers = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(df_helpers)\n",
    "\n",
    "# 使用模块中的函数\n",
    "#documents2Dataframe = df_helpers.documents2Dataframe\n",
    "print(\"Module imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe of all the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AbstractText-based Person Search (TBPS) aims t...</td>\n",
       "      <td>data_input\\cureus\\3.txt</td>\n",
       "      <td>8cae603439ee4c8abc10bb26dcf67cd4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>available at https://github.com/Flame-Chasers/...</td>\n",
       "      <td>data_input\\cureus\\3.txt</td>\n",
       "      <td>793e33ea22794c428acd1099139baada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>for solving these tasks. Considering that the ...</td>\n",
       "      <td>data_input\\cureus\\3.txt</td>\n",
       "      <td>468073942e8a48ff95077313de58f404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tion of random horizontal flip for the image w...</td>\n",
       "      <td>data_input\\cureus\\3.txt</td>\n",
       "      <td>3584388e37e1420e8413c2d91b216d67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>augmentations, and loss functions into CLIP. T...</td>\n",
       "      <td>data_input\\cureus\\3.txt</td>\n",
       "      <td>34a7ec0f07fe4a5196655586cb15bea5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                   source  \\\n",
       "0  AbstractText-based Person Search (TBPS) aims t...  data_input\\cureus\\3.txt   \n",
       "1  available at https://github.com/Flame-Chasers/...  data_input\\cureus\\3.txt   \n",
       "2  for solving these tasks. Considering that the ...  data_input\\cureus\\3.txt   \n",
       "3  tion of random horizontal flip for the image w...  data_input\\cureus\\3.txt   \n",
       "4  augmentations, and loss functions into CLIP. T...  data_input\\cureus\\3.txt   \n",
       "\n",
       "                           chunk_id  \n",
       "0  8cae603439ee4c8abc10bb26dcf67cd4  \n",
       "1  793e33ea22794c428acd1099139baada  \n",
       "2  468073942e8a48ff95077313de58f404  \n",
       "3  3584388e37e1420e8413c2d91b216d67  \n",
       "4  34a7ec0f07fe4a5196655586cb15bea5  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from helpers.df_helpers import documents2Dataframe\n",
    "df = documents2Dataframe(pages)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function uses the helpers/prompt function to extract concepts from text\n",
    "from helpers.df_helpers import df2Graph\n",
    "from helpers.df_helpers import graph2Df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If regenerate is set to True then the dataframes are regenerated and Both the dataframes are written in the csv format so we dont have to calculate them again. \n",
    "\n",
    "        dfne = dataframe of edges\n",
    "\n",
    "        df = dataframe of chunks\n",
    "\n",
    "\n",
    "Else the dataframes are read from the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\社会主义接班人\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>edge</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstracttext-based person search (tbps)</td>\n",
       "      <td>natural language descriptions</td>\n",
       "      <td>TBPS aims to retrieve the person images using ...</td>\n",
       "      <td>8cae603439ee4c8abc10bb26dcf67cd4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abstracttext-based person search (tbps)</td>\n",
       "      <td>clip</td>\n",
       "      <td>facing the rise of research on the CLIP-based ...</td>\n",
       "      <td>8cae603439ee4c8abc10bb26dcf67cd4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>clip</td>\n",
       "      <td>tbps</td>\n",
       "      <td>conduct a comprehensive empirical study of CLI...</td>\n",
       "      <td>8cae603439ee4c8abc10bb26dcf67cd4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clip</td>\n",
       "      <td>downstream tasks</td>\n",
       "      <td>performed over various cross-modal downstream ...</td>\n",
       "      <td>8cae603439ee4c8abc10bb26dcf67cd4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tbps</td>\n",
       "      <td>clip</td>\n",
       "      <td>make the first attempt to conduct a comprehens...</td>\n",
       "      <td>8cae603439ee4c8abc10bb26dcf67cd4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    node_1                         node_2  \\\n",
       "0  abstracttext-based person search (tbps)  natural language descriptions   \n",
       "1  abstracttext-based person search (tbps)                           clip   \n",
       "2                                     clip                           tbps   \n",
       "3                                     clip               downstream tasks   \n",
       "4                                     tbps                           clip   \n",
       "\n",
       "                                                edge  \\\n",
       "0  TBPS aims to retrieve the person images using ...   \n",
       "1  facing the rise of research on the CLIP-based ...   \n",
       "2  conduct a comprehensive empirical study of CLI...   \n",
       "3  performed over various cross-modal downstream ...   \n",
       "4  make the first attempt to conduct a comprehens...   \n",
       "\n",
       "                           chunk_id  count  \n",
       "0  8cae603439ee4c8abc10bb26dcf67cd4      4  \n",
       "1  8cae603439ee4c8abc10bb26dcf67cd4      4  \n",
       "2  8cae603439ee4c8abc10bb26dcf67cd4      4  \n",
       "3  8cae603439ee4c8abc10bb26dcf67cd4      4  \n",
       "4  8cae603439ee4c8abc10bb26dcf67cd4      4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To regenerate the graph with LLM, set this to True\n",
    "regenerate = True\n",
    "\n",
    "if regenerate:\n",
    "    concepts_list = df2Graph(df, model='gpt-4')\n",
    "    dfg1 = graph2Df(concepts_list)\n",
    "    if not os.path.exists(outputdirectory):\n",
    "        os.makedirs(outputdirectory)\n",
    "    \n",
    "    dfg1.to_csv(outputdirectory/\"3_graph.csv\", sep=\"|\", index=False)\n",
    "    df.to_csv(outputdirectory/\"3_chunks.csv\", sep=\"|\", index=False)\n",
    "else:\n",
    "    dfg1 = pd.read_csv(outputdirectory/\"graph.csv\", sep=\"|\")\n",
    "\n",
    "dfg1.replace(\"\", np.nan, inplace=True)\n",
    "dfg1.dropna(subset=[\"node_1\", \"node_2\", 'edge'], inplace=True)\n",
    "dfg1['count'] = 4 \n",
    "## Increasing the weight of the relation to 4. \n",
    "## We will assign the weight of 1 when later the contextual proximity will be calculated.  \n",
    "print(dfg1.shape)\n",
    "dfg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating contextual proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>count</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>wang</td>\n",
       "      <td>tbps-clip</td>\n",
       "      <td>559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...</td>\n",
       "      <td>3</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>wang</td>\n",
       "      <td>vit-b/16</td>\n",
       "      <td>559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>wang</td>\n",
       "      <td>vit-b/32</td>\n",
       "      <td>559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>word</td>\n",
       "      <td>sentence</td>\n",
       "      <td>ce8d1721d4a4428ebecff43790d12d9a,ce8d1721d4a44...</td>\n",
       "      <td>3</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4120</th>\n",
       "      <td>word</td>\n",
       "      <td>trivialaugment</td>\n",
       "      <td>ce8d1721d4a4428ebecff43790d12d9a,ce8d1721d4a44...</td>\n",
       "      <td>2</td>\n",
       "      <td>contextual proximity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     node_1          node_2  \\\n",
       "4103   wang       tbps-clip   \n",
       "4105   wang        vit-b/16   \n",
       "4106   wang        vit-b/32   \n",
       "4117   word        sentence   \n",
       "4120   word  trivialaugment   \n",
       "\n",
       "                                               chunk_id  count  \\\n",
       "4103  559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...      3   \n",
       "4105  559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...      2   \n",
       "4106  559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...      2   \n",
       "4117  ce8d1721d4a4428ebecff43790d12d9a,ce8d1721d4a44...      3   \n",
       "4120  ce8d1721d4a4428ebecff43790d12d9a,ce8d1721d4a44...      2   \n",
       "\n",
       "                      edge  \n",
       "4103  contextual proximity  \n",
       "4105  contextual proximity  \n",
       "4106  contextual proximity  \n",
       "4117  contextual proximity  \n",
       "4120  contextual proximity  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def contextual_proximity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ## Melt the dataframe into a list of nodes\n",
    "    dfg_long = pd.melt(\n",
    "        df, id_vars=[\"chunk_id\"], value_vars=[\"node_1\", \"node_2\"], value_name=\"node\"\n",
    "    )\n",
    "    dfg_long.drop(columns=[\"variable\"], inplace=True)\n",
    "    # Self join with chunk id as the key will create a link between terms occuring in the same text chunk.\n",
    "    dfg_wide = pd.merge(dfg_long, dfg_long, on=\"chunk_id\", suffixes=(\"_1\", \"_2\"))\n",
    "    # drop self loops\n",
    "    self_loops_drop = dfg_wide[dfg_wide[\"node_1\"] == dfg_wide[\"node_2\"]].index\n",
    "    dfg2 = dfg_wide.drop(index=self_loops_drop).reset_index(drop=True)\n",
    "    ## Group and count edges.\n",
    "    dfg2 = (\n",
    "        dfg2.groupby([\"node_1\", \"node_2\"])\n",
    "        .agg({\"chunk_id\": [\",\".join, \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    dfg2.columns = [\"node_1\", \"node_2\", \"chunk_id\", \"count\"]\n",
    "    dfg2.replace(\"\", np.nan, inplace=True)\n",
    "    dfg2.dropna(subset=[\"node_1\", \"node_2\"], inplace=True)\n",
    "    # Drop edges with 1 count\n",
    "    dfg2 = dfg2[dfg2[\"count\"] != 1]\n",
    "    dfg2[\"edge\"] = \"contextual proximity\"\n",
    "    return dfg2\n",
    "\n",
    "\n",
    "dfg2 = contextual_proximity(dfg1)\n",
    "dfg2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge both the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_1</th>\n",
       "      <th>node_2</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>edge</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(in, tn)</td>\n",
       "      <td>c-itc</td>\n",
       "      <td>bca3cb26c7fc44a08194fd70b87a6a27,bca3cb26c7fc4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ip, tp)</td>\n",
       "      <td>(in, tn)</td>\n",
       "      <td>bca3cb26c7fc44a08194fd70b87a6a27</td>\n",
       "      <td>The paired cross-modal data (Ip, Tp) and (In, ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(ip, tp)</td>\n",
       "      <td>c-itc</td>\n",
       "      <td>bca3cb26c7fc44a08194fd70b87a6a27,bca3cb26c7fc4...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ablation studies</td>\n",
       "      <td>comparisons</td>\n",
       "      <td>eb7f8f3132364c8ab3ee040bef09dcf6,eb7f8f3132364...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ablation studies</td>\n",
       "      <td>experimental analyses</td>\n",
       "      <td>eb7f8f3132364c8ab3ee040bef09dcf6,eb7f8f3132364...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>wang</td>\n",
       "      <td>vit-b/16</td>\n",
       "      <td>559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>wang</td>\n",
       "      <td>vit-b/32</td>\n",
       "      <td>559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>word</td>\n",
       "      <td>sentence</td>\n",
       "      <td>ce8d1721d4a4428ebecff43790d12d9a,ce8d1721d4a44...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>word</td>\n",
       "      <td>trivialaugment</td>\n",
       "      <td>ce8d1721d4a4428ebecff43790d12d9a,ce8d1721d4a44...</td>\n",
       "      <td>contextual proximity</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>‘stacking together’</td>\n",
       "      <td>multiple losses</td>\n",
       "      <td>ab8dde21fe0f494781db72e292be2a68</td>\n",
       "      <td>‘Stacking Together’ denotes that multiple loss...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1668 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   node_1                 node_2  \\\n",
       "0                (in, tn)                  c-itc   \n",
       "1                (ip, tp)               (in, tn)   \n",
       "2                (ip, tp)                  c-itc   \n",
       "3        ablation studies            comparisons   \n",
       "4        ablation studies  experimental analyses   \n",
       "...                   ...                    ...   \n",
       "1663                 wang               vit-b/16   \n",
       "1664                 wang               vit-b/32   \n",
       "1665                 word               sentence   \n",
       "1666                 word         trivialaugment   \n",
       "1667  ‘stacking together’        multiple losses   \n",
       "\n",
       "                                               chunk_id  \\\n",
       "0     bca3cb26c7fc44a08194fd70b87a6a27,bca3cb26c7fc4...   \n",
       "1                      bca3cb26c7fc44a08194fd70b87a6a27   \n",
       "2     bca3cb26c7fc44a08194fd70b87a6a27,bca3cb26c7fc4...   \n",
       "3     eb7f8f3132364c8ab3ee040bef09dcf6,eb7f8f3132364...   \n",
       "4     eb7f8f3132364c8ab3ee040bef09dcf6,eb7f8f3132364...   \n",
       "...                                                 ...   \n",
       "1663  559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...   \n",
       "1664  559b39db23c6432381c2a4c0d0166e0a,559b39db23c64...   \n",
       "1665  ce8d1721d4a4428ebecff43790d12d9a,ce8d1721d4a44...   \n",
       "1666  ce8d1721d4a4428ebecff43790d12d9a,ce8d1721d4a44...   \n",
       "1667                   ab8dde21fe0f494781db72e292be2a68   \n",
       "\n",
       "                                                   edge  count  \n",
       "0                                  contextual proximity      2  \n",
       "1     The paired cross-modal data (Ip, Tp) and (In, ...      4  \n",
       "2                                  contextual proximity      2  \n",
       "3                                  contextual proximity      2  \n",
       "4                                  contextual proximity      3  \n",
       "...                                                 ...    ...  \n",
       "1663                               contextual proximity      2  \n",
       "1664                               contextual proximity      2  \n",
       "1665                               contextual proximity      3  \n",
       "1666                               contextual proximity      2  \n",
       "1667  ‘Stacking Together’ denotes that multiple loss...      4  \n",
       "\n",
       "[1668 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg = pd.concat([dfg1, dfg2], axis=0)\n",
    "dfg = (\n",
    "    dfg.groupby([\"node_1\", \"node_2\"])\n",
    "    .agg({\"chunk_id\": \",\".join, \"edge\": ','.join, 'count': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "dfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the NetworkX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = pd.concat([dfg['node_1'], dfg['node_2']], axis=0).unique()\n",
    "nodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "\n",
    "## Add nodes to the graph\n",
    "for node in nodes:\n",
    "    G.add_node(\n",
    "        str(node)\n",
    "    )\n",
    "\n",
    "## Add edges to the graph\n",
    "for index, row in dfg.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"node_1\"]),\n",
    "        str(row[\"node_2\"]),\n",
    "        title=row[\"edge\"],\n",
    "        weight=row['count']/4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate communities for coloring the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Communities =  5\n",
      "[['(in, tn)', '(ip, tp)', 'abstracttext-based person search (tbps)', 'academia and industry', 'albef', 'bai et al.', 'baseline', 'bert', 'c-itc', 'cfine', 'clip', 'clip-adapter', 'clip-based tbps method', 'cmpm (zhang and lu 2018)', 'coop', 'cross-modal correspondence', 'cross-modal tasks', 'cross-modality regularization', 'cyclip (goel et al. 2022)', 'data augmentation', 'declip', 'dkl(pi,j∥ˆqi,j) + dkl(pj,i∥ˆqj,i)', 'dkl(p∥q)', 'downstream tasks', 'dropping operation', 'empirical study', 'empirical study on data augmentation and loss function', 'epochalbef', 'few-shot capabilities', 'few-shot clip variants', 'few-shot tbps', 'figure 3', 'filip', 'geometry of the resulting representation space', 'grant nsfc 62002252', 'icfg-pedes', 'image encoder', 'image-text contrastive loss (c-itc)', 'image-text retrieval', 'in-modality regularization', 'irra', 'ivt', 'jiang', 'jiang and ye 2023', 'lcc−it c', 'lci−it c', 'learned representations', 'lgur', 'lr−it c', 'lstm', 'methodsbaselinesparam', 'metrics', 'model generalization', 'multimodal interaction encoder', 'national science foundation of china', 'natural language descriptions', 'person re-identification', 'poor performance', 'pre-training', 'priority academic program development of jiangsu higher education institutions', 'radford et al.', 'rasa', 'resnet-50', 'rstpreid', 's. tbps-clip', 'saf', 'similarity probability', 'simplified tbps-clip', 'simplified version', 'slip', 'small amount of tbps training data', 'specific losses', 'ssan', 'tasks', 'tbps', 'tbps community', 'tbps methods', 'tbps solutions', 'tbps-clip', 'text encoder', 'text feature encoding', 'this paper', 'tp-tps', 'unimodal pre-trained models', 'vit', 'vit-b/16', 'vit-b/32', 'vitaa', 'vlp', 'wang'], ['ablation studies', 'age precision', 'alteration', 'appendix', 'augmentation', 'augmentation pool', 'augmentation pool strategy', 'augmentations', 'augmented data view', 'autoaug', 'autoaugment', 'back translation', 'clip∗', 'color information', 'colorjitter', 'colorjitter-bcs', 'colorjitter-hue', 'common technologies', 'comparisons', 'contents', 'cubuk et al. 2018', 'cubuk et al. 2020', 'cuhk-pedes', 'data augmentation strategies', 'data augmentations', 'data efficiency', 'dataset', 'dropout', 'eda', 'empirical studies', 'evaluation metric', 'experimental analyses', 'feature representations', 'figure 1.3.1', 'gaussianblur', 'global gradients back-propagation', 'hyperparameters', 'image', 'image and text', 'image augmentation', 'image augmentations', 'image-text contrastive loss', 'image-text pair', 'label', 'locking bottom layers', 'loss', 'loss function', 'loss functions', 'm', 'magnitude', 'map', 'model', 'model compression', \"module's contribution\", \"module's importance\", 'multiple augmentations', 'mvs-i', 'mvs-it', 'mvs-t', 'm¨uller', 'n', 'n-itc', 'number of augmentations', 'optimal augmentations', 'original image', 'original text', 'other methods', 'performance', 'performance evaluation', 'randaug', 'randaugment', 'random', 'random deletion', 'random horizontal flip', 'random insertion', 'random swap', 'randomerasing', 'randomgrayscale', 'randomhorizontalflip', 'randomresizedcrop', 'randomrota-tion', 'randomrotation', 'randomverticalflip', 'rank-1', 'rank-k and mean average precision (map)', 'removal', 'removal augmentations', 'research direction', 'results', 'sample', 'self-supervised loss', 'sentence', 'similarity', 'soft label', 'ss', 'ss-i', 'stacking together', 'synonym replacement', 'table 1', 'table 2', 'table 5', 'tbps-specific view', 'text', 'text augmentation', 'training tricks', 'tricks', 'trivialaug', 'trivialaugment', 'word'], ['challenges', 'cross-modal alignment', 'fine-grained retrieval task', 'large-scale image database', 'lost children', 'methods', 'representations', 'research', 'suspects', 'text-based person search (tbps)', 'textual description', 'vlp for tbps', 'vlp methods', 'vlp models'], ['clip+aug', 'r-itc'], ['multiple losses', '‘stacking together’']]\n"
     ]
    }
   ],
   "source": [
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe for community colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>color</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(in, tn)</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(ip, tp)</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abstracttext-based person search (tbps)</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academia and industry</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>albef</td>\n",
       "      <td>#5784db</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>vlp models</td>\n",
       "      <td>#57db94</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>clip+aug</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>r-itc</td>\n",
       "      <td>#b9db57</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>multiple losses</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>‘stacking together’</td>\n",
       "      <td>#db5f57</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        node    color  group\n",
       "0                                   (in, tn)  #5784db      1\n",
       "1                                   (ip, tp)  #5784db      1\n",
       "2    abstracttext-based person search (tbps)  #5784db      1\n",
       "3                      academia and industry  #5784db      1\n",
       "4                                      albef  #5784db      1\n",
       "..                                       ...      ...    ...\n",
       "212                               vlp models  #57db94      3\n",
       "213                                 clip+aug  #b9db57      4\n",
       "214                                    r-itc  #b9db57      4\n",
       "215                          multiple losses  #db5f57      5\n",
       "216                      ‘stacking together’  #db5f57      5\n",
       "\n",
       "[217 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "palette = \"hls\"\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    random.shuffle(p)\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"node\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)\n",
    "colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add colors to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in colors.iterrows():\n",
    "    G.nodes[row['node']]['group'] = row['group']\n",
    "    G.nodes[row['node']]['color'] = row['color']\n",
    "    G.nodes[row['node']]['size'] = G.degree[row['node']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "\n",
    "graph_output_directory = \"./docs/3_index.html\"\n",
    "\n",
    "net = Network(\n",
    "    notebook=False,\n",
    "    # bgcolor=\"#1a1a1a\",\n",
    "    cdn_resources=\"remote\",\n",
    "    height=\"900px\",\n",
    "    width=\"100%\",\n",
    "    select_menu=True,\n",
    "    # font_color=\"#cccccc\",\n",
    "    filter_menu=False,\n",
    ")\n",
    "\n",
    "net.from_nx(G)\n",
    "# net.repulsion(node_distance=150, spring_length=400)\n",
    "net.force_atlas_2based(central_gravity=0.015, gravity=-31)\n",
    "# net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "net.show_buttons(filter_=[\"physics\"])\n",
    "html_content = net.generate_html()\n",
    "\n",
    "# Write the HTML content to a file with UTF-8 encoding\n",
    "with open(graph_output_directory, 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "# net.show(graph_output_directory, notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 保存节点信息\n",
    "nodes_data = []\n",
    "for node in G.nodes(data=True):\n",
    "    nodes_data.append({\n",
    "        'node': node[0],\n",
    "        'group': node[1].get('group'),\n",
    "        'color': node[1].get('color'),\n",
    "        'size': node[1].get('size')\n",
    "    })\n",
    "\n",
    "df_nodes = pd.DataFrame(nodes_data)\n",
    "df_nodes.to_csv(\"nodes_data.csv\", index=False)\n",
    "\n",
    "# 保存边信息\n",
    "edges_data = []\n",
    "for edge in G.edges(data=True):\n",
    "    edges_data.append({\n",
    "        'node_1': edge[0],\n",
    "        'node_2': edge[1],\n",
    "        'weight': edge[2].get('weight')\n",
    "    })\n",
    "\n",
    "df_edges = pd.DataFrame(edges_data)\n",
    "df_edges.to_csv(\"edges_data.csv\", index=False)\n",
    "communities_data = []\n",
    "for group, community in enumerate(communities, 1):\n",
    "    for node in community:\n",
    "        communities_data.append({'node': node, 'group': group})\n",
    "\n",
    "df_communities = pd.DataFrame(communities_data)\n",
    "df_communities.to_csv(\"communities_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI@3111",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
