node_1,node_2,weight
3 cars,cars,
3 cars,episodes,
3 cars,method,
3 cars,methods,
3 cars,nested reasoning,
3 cars,tomnet’s accuracy,
3 normal cars condition,our method,
4 cars,cars,
4 cars,episodes,
4 cars,method,
4 cars,methods,
4 cars,nested reasoning,
4 cars,tomnet’s accuracy,
9 particles,our method,
accelerate,action,
accelerate,generalization testing sets,
accelerate,training sets,
accelerating probabilistic inference,neural amortized inference,
accuracy,hypotheses,
accuracy,method,
accuracy,model,
accuracy,network,
accuracy,particles,
accuracy,tomnet,
accurate,hypotheses,
accurate,method,
accurate,network,
accurate,tomnet,
action,action prediction,
action,brake,
action,comparison,
action,driver,
action,evaluation,
action,exact inference,
action,generalization testing sets,
action,goal,
action,honking,
action,i) 4 cars,
action,i-pomdp,
action,ii) 3 cars with inattentive driver,
action,level-1 agent policy,
action,"method (ours) against ei, tomnet, and ours-nn",
action,rotate left,
action,rotate right,
action,s0,
action,s1,
action,s2,
action,testing episodes,
action,training sets,
action,car,
action prediction,generalization testing sets,
action prediction,level-1 agent policy,
action prediction,method,
action prediction,training sets,
action prediction accuracy,cars,
action prediction accuracy,episodes,
action prediction accuracy,method,
action prediction accuracy,methods,
action prediction accuracy,nested reasoning,
action prediction accuracy,tomnet’s accuracy,
actions,agent j,
actions,agents,
actions,ego agent,
adjusts,alice,
adjusts,bob,
adjusts,method,
adjusts,ours,
agent,autonomous agents,
agent,block,
agent,complex domains,
agent,episode,
agent,goal,
agent,i-pomdp,
agent,inference,
agent,interactive partially observable markov decision making process (i-pomdp),
agent,model,
agent,multi-agent system,
agent,multi-agent systems,
agent,nested reasoning,
agent,observer,
agent,planner,
agent,recursive inference,
agent,step,
agent,testing episodes,
agent,training set,
agent i,agent j,
agent i,agents,
agent i,ego agent,
agent i,goal,
agent j,agents,
agent j,agents' behavior,
agent j,beliefs,
agent j,ego agent,
agent j,environment,
agent j,generative model,
agent j,goal,
agent j,i-pomdp,
agent j,i-pomdp model,
agent j,information,
agent j,interactive state,
agent j,level-ℓ,
agent j,mind,
agent j,nested reasoning,
agent j,particle sampling,
agent j,pomdp,
agent j,recognition networks,
agent j,states,
agent j,steps,
agents,agents' behavior,
agents,beliefs,
agents,ego agent,
agents,environment,
agents,generative model,
agents,goal,
agents,i-pomdp,
agents,i-pomdp model,
agents,information,
agents,interactive state,
agents,level-ℓ,
agents,mind,
agents,nested reasoning,
agents,particle sampling,
agents,pomdp,
agents,recognition networks,
agents,states,
agents,steps,
agents' behavior,ego agent,
agents' behavior,generative model,
ai systems,method,
ai systems,multi-agent interactions,
ai systems,reasoning,
ai systems,social inference,
alice,block,
alice,bob,
alice,inference,
alice,method,
alice,ours,
alice,ours-nn,
alice,tomnet,
alice,yellow and teal blocks,
amortized inference,cooperative inverse reinforcement learning (cirl),
amortized inference,gmytrasiewicz and doshi (2005),
amortized inference,human-robot cooperation,
amortized inference,inference,
amortized inference,interactive partially observable markov decision process (i-pomdp),
amortized inference,lower level inference,
amortized inference,nested goal and belief inference,
amortized inference,nested multi-agent reasoning,
amortized inference,nested reasoning between multi-agents,
amortized inference,planning,
amortized inference,recognition model,
amortized inference,recogniton model,
amortized inference,training,
amortized inference,uncertainty in inference,
amortized inference,user needs to infer,
amortized inference,neurally-guided procedural models,
"approximate the posterior belief bt i,ℓ",block,
"approximate the posterior belief bt i,ℓ",weighted samples,
autonomous agents,i-pomdp,
autonomous agents,nested reasoning,
autonomous agents,probabilistic programs,
averaged action prediction accuracy,our method,
averaged action prediction accuracy,progress of an episode,
bayesian models,social goal inference,
bayesian theory of mind,neural amortized inference,
bayesian theory of mind,generative models,
belief,goal inference,
belief,importance sampling,
belief,importance weight,
belief,inference,
belief,level,
belief,observation,
belief,particle,
belief,particles,
belief,planning,
belief,posterior,
belief,prior,
belief,recognition distribution,
belief,recognition model,
belief,recognition networks,
belief,samples,
belief,set,
belief,state inference,
belief bt,block,
belief bt,importance sampling,
beliefs,ego agent,
block,bob,
block,construction environment,
block,driver,
block,experiments,
block,goal,
block,importance sampling,
block,importance sampling at every step,
block,importance sampling at every time step,
block,inference,
block,model,
block,sampling procedure,
block,sequential monte carlo,
block,weighted samples,
bluffing,method,
bluffing,multi-agent interactions,
bluffing,reasoning,
bluffing,social inference,
bob,driver,
bob,goal,
bob,inference,
bob,method,
bob,ours,
bob,ours-nn,
bob,tomnet,
bob,yellow and teal blocks,
brake,generalization testing sets,
brake,training sets,
branch,inference,
branch,level,
branch,planning,
car,driver,
car,environment,
car,goal,
car,model,
car,planner,
car,world state,
carlo,driver,
carlo,goal,
carlo,environment,
cars,complex multi-agent interactions,
cars,episodes,
cars,exact inference,
cars,figure 8c,
cars,generalizability,
cars,inattentive driver,
cars,method,
cars,methods,
cars,nested reasoning,
cars,tomnet’s accuracy,
certainty,driver,
certainty,goal,
certainty,model,
communication,method,
communication,multi-agent interactions,
communication,reasoning,
communication,social inference,
comparison,generalization testing sets,
comparison,"method (ours) against ei, tomnet, and ours-nn",
comparison,training sets,
complex domains,i-pomdp,
complex domains,nested reasoning,
complex multi-agent interactions,episodes,
complex multi-agent interactions,method,
complex multi-agent interactions,methods,
complex multi-agent interactions,nested reasoning,
complex multi-agent interactions,tomnet’s accuracy,
computational complexity,method,
computational complexity,multi-agent interactions,
computational complexity,reasoning,
computational complexity,social inference,
conference on robot learning,pmlr,
confidence,method,
confidence,hypotheses,
construction environment,experiments,
conventional methods,end-to-end model,
conventional methods,nested reasoning,
cooperative inverse reinforcement learning (cirl),gmytrasiewicz and doshi (2005),
cooperative inverse reinforcement learning (cirl),human-robot cooperation,
cooperative inverse reinforcement learning (cirl),interactive partially observable markov decision process (i-pomdp),
cooperative inverse reinforcement learning (cirl),nested goal and belief inference,
cooperative inverse reinforcement learning (cirl),nested multi-agent reasoning,
cooperative inverse reinforcement learning (cirl),nested reasoning between multi-agents,
cooperative inverse reinforcement learning (cirl),uncertainty in inference,
cooperative inverse reinforcement learning (cirl),user needs to infer,
crashing,driver,
crashing,goal,
cross-entropy loss,uniform distribution,
darpa machine common sense program,onr muri n00014-13-1-0333,
data generation,training data,
data-driven proposals,uniform distribution,
data-driven proposals,recognition network,
domain,method,
domain,multi-agent interaction,
driver,environment,
driver,experiment,
driver,goal,
driver,inference,
driver,model,
driver,multi-agent nested reasoning,
driver,observation,
driver,planner,
driver,traffic,
driver,uncertainty estimation,
driver,world state,
driving domain,drivers,
efficiency of nested reasoning,our method,
ego agent,environment,
ego agent,generative model,
ego agent,goal,
ego agent,i-pomdp,
ego agent,i-pomdp model,
ego agent,information,
ego agent,interactive state,
ego agent,level-ℓ,
ego agent,mind,
ego agent,nested reasoning,
ego agent,particle sampling,
ego agent,pomdp,
ego agent,recognition networks,
ego agent,states,
ego agent,steps,
ei,hypotheses,
ei,method,
ei,network,
ei,tomnet,
ei performance,uniform distribution,
ei performance,exact inference,
end-to-end methods,end-to-end model,
end-to-end methods,model-based methods,
end-to-end methods,nested reasoning,
end-to-end model,han and gmytrasiewicz,
end-to-end model,model-based methods,
end-to-end model,nested multi-agent reasoning,
end-to-end model,nested reasoning,
end-to-end model,theory of mind reasoning,
end-to-end model,uncertainty in inference,
environment,goal,
environment,model,
episodes,exact inference,
episodes,figure 8c,
episodes,generalizability,
episodes,inattentive driver,
episodes,method,
episodes,methods,
episodes,nested reasoning,
episodes,tomnet’s accuracy,
evaluation,generalization testing sets,
evaluation,testing episodes,
evaluation,training sets,
exact inference,generalization testing sets,
exact inference,method,
exact inference,methods,
exact inference,nested reasoning,
exact inference,our method,
exact inference,tomnet’s accuracy,
exact inference,training sets,
exact inference,uniform distribution,
exact inference,i-pomdp,
exact inference,model inference,
experiment,goal,
experiment,traffic,
experimental results,method,
experimental results,multi-agent interactions,
experimental results,reasoning,
experimental results,social inference,
figure 8c,method,
figure 8c,methods,
figure 8c,nested reasoning,
figure 8c,tomnet’s accuracy,
generalizability,method,
generalizability,methods,
generalizability,nested reasoning,
generalizability,tomnet’s accuracy,
generalization evaluation results,our method,
generalization evaluation results,models trained with 3 cars controlled by normal drivers,
generalization testing sets,honking,
generalization testing sets,i) 4 cars,
generalization testing sets,i-pomdp,
generalization testing sets,ii) 3 cars with inattentive driver,
generalization testing sets,level-1 agent policy,
generalization testing sets,"method (ours) against ei, tomnet, and ours-nn",
generalization testing sets,rotate left,
generalization testing sets,rotate right,
generalization testing sets,s0,
generalization testing sets,s1,
generalization testing sets,s2,
generalization testing sets,testing episodes,
generalization testing sets,training sets,
generative model,inference,
generative model,level,
generative model,planning,
generative model,observations,
generative models,neural amortized inference,
gmytrasiewicz and doshi (2005),human-robot cooperation,
gmytrasiewicz and doshi (2005),interactive partially observable markov decision process (i-pomdp),
gmytrasiewicz and doshi (2005),nested goal and belief inference,
gmytrasiewicz and doshi (2005),nested multi-agent reasoning,
gmytrasiewicz and doshi (2005),nested reasoning between multi-agents,
gmytrasiewicz and doshi (2005),uncertainty in inference,
gmytrasiewicz and doshi (2005),user needs to infer,
goal,hypotheses,
goal,i-pomdp,
goal,inference,
goal,method,
goal,model,
goal,multi-agent nested reasoning,
goal,nested reasoning,
goal,network,
goal,observation,
goal,tomnet,
goal,traffic,
goal,uncertainty estimation,
goal inference,importance sampling,
goal inference,recognition distribution,
goal inference,recognition model,
green,method,
green,red,
green infers red’s goal and belief,our method,
green's action,method,
green's action,method's prediction,
han and gmytrasiewicz,nested reasoning,
high-order social inference,method,
high-order social inference,multi-agent interactions,
high-order social inference,reasoning,
high-order social inference,social inference,
high-order social inference,neural networks,
honking,training sets,
human-robot cooperation,interactive partially observable markov decision process (i-pomdp),
human-robot cooperation,nested goal and belief inference,
human-robot cooperation,nested multi-agent reasoning,
human-robot cooperation,uncertainty in inference,
humans,method,
humans,multi-agent interactions,
humans,reasoning,
humans,social inference,
hypotheses,method,
hypotheses,model,
hypotheses,network,
hypotheses,ours,
hypotheses,particles,
hypotheses,planning,
hypotheses,reasoning,
hypotheses,tomnet,
i) 4 cars,training sets,
i-pomdp,interactive partially observable markov decision making process (i-pomdp),
i-pomdp,interactive partially observable markov decision process,
i-pomdp,multi-agent system,
i-pomdp,multi-agent systems,
i-pomdp,nested reasoning,
i-pomdp,neural amortized inference,
i-pomdp,neural networks,
i-pomdp,pomdp,
i-pomdp,recursive inference,
i-pomdp,training sets,
i-pomdp formulation,neural amortized inference,
i-pomdp model,states,
ii) 3 cars with inattentive driver,training sets,
importance sampling,importance weight,
importance sampling,level,
importance sampling,particle,
importance sampling,particles,
importance sampling,posterior,
importance sampling,prior,
importance sampling,recognition distribution,
importance sampling,recognition model,
importance sampling,recognition networks,
importance sampling,samples,
importance sampling,set,
importance sampling,state inference,
importance sampling at every step,sequential monte carlo,
importance sampling at every time step,sampling procedure,
importance weight,particle,
importance weight,recognition distribution,
importance weight,recognition model,
inattentive driver,method,
inattentive driver,methods,
inattentive driver,nested reasoning,
inattentive driver,tomnet’s accuracy,
inference,level,
inference,lower level inference,
inference,meta-learning,
inference,method,
inference,model,
inference,observations,
inference,ours,
inference,planning,
inference,recognition model,
inference,recogniton model,
inference,training,
information,mind,
interactive partially observable markov decision making process (i-pomdp),multi-agent systems,
interactive partially observable markov decision making process (i-pomdp),nested reasoning,
interactive partially observable markov decision process,neural amortized inference,
interactive partially observable markov decision process (i-pomdp),nested goal and belief inference,
interactive partially observable markov decision process (i-pomdp),nested multi-agent reasoning,
interactive partially observable markov decision process (i-pomdp),nested reasoning between multi-agents,
interactive partially observable markov decision process (i-pomdp),uncertainty in inference,
interactive partially observable markov decision process (i-pomdp),user needs to infer,
interactive pomdps,exact solutions,
interactive state,level-ℓ,
kl-divergence,method,
kl-divergence,model,
kl-divergence,uncertainty estimation,
lack of robust nested reasoning,our method,
lack of robust nested reasoning,tomnet,
level,observations,
level,planning,
level,recognition distribution,
level,recognition model,
level-1 agent policy,training sets,
level-1 goal inference,level-2 goal inference,
level-1 goal inference,uniform distribution,
level-2 goal inference,uniform distribution,
level-2 reasoning,method,
level-2 reasoning,real-world social reasoning,
lockheed martin,grant,
machine theory of mind,international conference on machine learning,
meta-learning,method,
method,method's prediction,
method,methods,
method,model,
method,multi-agent interaction,
method,multi-agent interaction domains,
method,multi-agent interactions,
method,nested reasoning,
method,network,
method,neural networks,
method,ours,
method,ours-nn,
method,particles,
method,planning,
method,real-world social reasoning,
method,reasoning,
method,recognition network,
method,recursive nature,
method,red,
method,social inference,
method,teaching,
method,tomnet,
method,tomnet’s accuracy,
method,understanding,
method,yellow and teal blocks,
"method (ours) against ei, tomnet, and ours-nn",training sets,
methods,nested reasoning,
methods,tomnet’s accuracy,
model,network,
model,particles,
model,planner,
model,tomnet,
model inference,our method,
model-based methods,nested reasoning,
model-based reasoning,neural amortized inference,
model-based reasoning,neural networks,
models trained with 3 cars controlled by normal drivers,our method,
multi-agent interaction domains,multi-agent interactions,
multi-agent interaction domains,reasoning,
multi-agent interaction domains,social inference,
multi-agent interactions,neural networks,
multi-agent interactions,reasoning,
multi-agent interactions,social inference,
multi-agent interactions,teaching,
multi-agent interactions,understanding,
multi-agent nested reasoning,uncertainty estimation,
multi-agent system,nested reasoning,
multi-agent systems,nested reasoning,
nested goal and belief inference,nested multi-agent reasoning,
nested goal and belief inference,nested reasoning between multi-agents,
nested goal and belief inference,uncertainty in inference,
nested goal and belief inference,user needs to infer,
nested multi-agent reasoning,nested reasoning,
nested multi-agent reasoning,nested reasoning between multi-agents,
nested multi-agent reasoning,our method,
nested multi-agent reasoning,theory of mind reasoning,
nested multi-agent reasoning,uncertainty in inference,
nested multi-agent reasoning,user needs to infer,
nested multi-agent reasoning,neural amortized inference approach,
nested reasoning,recursive inference,
nested reasoning,steps,
nested reasoning,theory of mind reasoning,
nested reasoning,tomnet’s accuracy,
nested reasoning,uncertainty in inference,
nested reasoning between multi-agents,uncertainty in inference,
network,ours,
network,particles,
network,planning,
network,reasoning,
network,tomnet,
neural amortized inference,neural networks,
neural amortized inference,proposal distribution,
neural amortized inference,uniform distribution,
neural amortized inference approach,our method,
neural networks,reasoning,
neural networks,social inference,
observations,planning,
online action pre,figure 10,
our method,progress of an episode,
our method,tomnet,
our method,uncertainty in its inference,
ours,ours-nn,
ours,tomnet,
ours,yellow and teal blocks,
ours-nn,uniform distribution,
particle,recognition distribution,
particle,recognition model,
particle sampling,recognition networks,
particles,recognition distribution,
particles,recognition model,
particles,tomnet,
planning,tomnet,
posterior,recognition distribution,
posterior,recognition model,
prior,recognition distribution,
prior,recognition model,
proposal distribution,uniform distribution,
reasoning,social inference,
reasoning,teaching,
reasoning,tomnet,
reasoning,understanding,
recognition distribution,recognition model,
recognition distribution,recognition networks,
recognition distribution,samples,
recognition distribution,set,
recognition distribution,state inference,
recognition model,factorization,
recognition model,recognition networks,
recognition model,samples,
recognition model,set,
recognition model,state inference,
recognition model,training,
recognition network,uniform distribution,
recursive mdps,social interactions,
rotate left,training sets,
rotate right,training sets,
s0,training sets,
s1,training sets,
s2,training sets,
social inference,teaching,
social inference,understanding,
testing episodes,training sets,
theory of minds,behavior in groups,
two-player game,2d grid worlds,
ullman,baker,
uncertainty in inference,user needs to infer,
